{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer, DebertaV2Tokenizer, DebertaV2ForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datasets import Dataset, load_metric\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_train_df = pd.read_csv('propaganda_train.tsv', delimiter='\\t', quotechar='\\'')\n",
    "task1_train_df.loc[task1_train_df['label'] != \"not_propaganda\", 'label'] = \"propaganda\" # All 8 Propaganda labels are changed to \"propaganda\" and the total number of classes is reduced to 2\n",
    "task1_train_df['tagged_in_context'] = task1_train_df['tagged_in_context'].str.replace('<BOS>', '', regex=False)\n",
    "task1_train_df['tagged_in_context'] = task1_train_df['tagged_in_context'].str.replace('<EOS>', '', regex=False)\n",
    "\n",
    "task1_test_df = pd.read_csv('propaganda_val.tsv', sep='\\t', quotechar='\\'') \n",
    "task1_test_df.loc[task1_test_df['label'] != \"not_propaganda\", 'label'] = \"propaganda\" # All 8 Propaganda labels are changed to \"propaganda\" and the total number of classes is reduced to 2\n",
    "task1_test_df['tagged_in_context'] = task1_test_df['tagged_in_context'].str.replace('<BOS>', '', regex=False)\n",
    "task1_test_df['tagged_in_context'] = task1_test_df['tagged_in_context'].str.replace('<EOS>', '', regex=False)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "task1_train_df['label'] = label_encoder.fit_transform(task1_train_df['label'])\n",
    "task1_test_df['label'] = label_encoder.transform(task1_test_df['label'])\n",
    "\n",
    "display(task1_train_df)\n",
    "display(task1_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_train_df = pd.read_csv('propaganda_train.tsv', delimiter='\\t', quotechar='\\'')\n",
    "task2_test_df = pd.read_csv('propaganda_val.tsv', delimiter='\\t', quotechar='\\'')\n",
    "\n",
    "task2_train_df = task2_train_df[task2_train_df['label'] != 'not_propaganda']\n",
    "task2_test_df = task2_test_df[task2_test_df['label'] != 'not_propaganda']\n",
    "\n",
    "for index, row in task2_train_df.iterrows():\n",
    "    bos_index = row['tagged_in_context'].index(\"<BOS>\")\n",
    "    eos_index = row['tagged_in_context'].index(\"<EOS>\")\n",
    "    task2_train_df.loc[index,'tagged_in_context'] = row['tagged_in_context'][bos_index + 5:eos_index]\n",
    "\n",
    "for index, row in task2_test_df.iterrows():\n",
    "    bos_index = row['tagged_in_context'].index(\"<BOS>\")\n",
    "    eos_index = row['tagged_in_context'].index(\"<EOS>\")\n",
    "    task2_test_df.loc[index,'tagged_in_context'] = row['tagged_in_context'][bos_index + 5:eos_index]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "task2_train_df['label'] = label_encoder.fit_transform(task2_train_df['label'])\n",
    "task2_test_df['label'] = label_encoder.transform(task2_test_df['label'])\n",
    "\n",
    "\n",
    "display(task2_train_df)\n",
    "display(task2_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK-1 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting class distributions\n",
    "\n",
    "class_counts_train = task1_train_df['label'].value_counts().sort_index()\n",
    "\n",
    "class_counts_test = task1_test_df['label'].value_counts().sort_index()\n",
    "\n",
    "df = pd.DataFrame({'Train': class_counts_train, 'Test': class_counts_test})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.plot(kind='barh', ax=plt.gca())\n",
    "plt.title('Class Distribution in Training and Test Sets')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()\n",
    "\n",
    "# Plotting maximum, minimum and average word counts of the datasets\n",
    "\n",
    "task1_train_df['word_count'] = task1_train_df['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "task1_test_df['word_count'] = task1_test_df['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "\n",
    "train_min = task1_train_df['word_count'].min()\n",
    "train_max = task1_train_df['word_count'].max()\n",
    "train_mean = task1_train_df['word_count'].mean()\n",
    "\n",
    "test_min = task1_test_df['word_count'].min()\n",
    "test_max = task1_test_df['word_count'].max()\n",
    "test_mean = task1_test_df['word_count'].mean()\n",
    "\n",
    "stats = pd.DataFrame({\n",
    "    'Train': [train_min, train_max, train_mean],\n",
    "    'Test': [test_min, test_max, test_mean]\n",
    "}, index=['Minimum', 'Maximum', 'Average'])\n",
    "\n",
    "stats.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Word Counts in Train and Test Sentences')\n",
    "plt.ylabel('Word Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK-2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting class distributions\n",
    "\n",
    "class_counts_train = task2_train_df['label'].value_counts().sort_index()\n",
    "\n",
    "class_counts_test = task2_test_df['label'].value_counts().sort_index()\n",
    "\n",
    "df = pd.DataFrame({'Train': class_counts_train, 'Test': class_counts_test})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.plot(kind='barh', ax=plt.gca())\n",
    "plt.title('Class Distribution in Training and Test Sets')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()\n",
    "\n",
    "# Plotting maximum, minimum and average word counts of the datasets\n",
    "\n",
    "task2_train_df['word_count'] = task2_train_df['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "task2_test_df['word_count'] = task2_test_df['tagged_in_context'].apply(lambda x: len(x.split()))\n",
    "\n",
    "train_min = task2_train_df['word_count'].min()\n",
    "train_max = task2_train_df['word_count'].max()\n",
    "train_mean = task2_train_df['word_count'].mean()\n",
    "\n",
    "test_min = task2_test_df['word_count'].min()\n",
    "test_max = task2_test_df['word_count'].max()\n",
    "test_mean = task2_test_df['word_count'].mean()\n",
    "\n",
    "stats = pd.DataFrame({\n",
    "    'Train': [train_min, train_max, train_mean],\n",
    "    'Test': [test_min, test_max, test_mean]\n",
    "}, index=['Minimum', 'Maximum', 'Average'])\n",
    "\n",
    "stats.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Word Counts in Train and Test Sentences')\n",
    "plt.ylabel('Word Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeBERTaV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "class DebertaV3():\n",
    "\n",
    "    def __init__(self,train,test,n_labels):\n",
    "\n",
    "        \"\"\"\n",
    "           Creates Dataset from train and test datasets. Creates model and tokenizer.\n",
    "           :param train: Train set\n",
    "           :param test: Test set\n",
    "           :param n_labels: Number of classes\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_labels = n_labels     \n",
    "        # Creating dataset, loading DeBERTaV3 model and tokenizer\n",
    "        self.train_dataset = Dataset.from_pandas(train)\n",
    "        self.test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "        device = torch.device(\"mps\")\n",
    "        model_name = \"microsoft/deberta-v3-base\"\n",
    "        self.tokenizer = DebertaV2Tokenizer.from_pretrained(model_name)\n",
    "        self.model = DebertaV2ForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\n",
    "        self.model.to(device)\n",
    "\n",
    "    def tokenize(self, data):\n",
    "        \"\"\"\n",
    "            It tokenizes the data given as parameters.\n",
    "            :param data: Train or test data\n",
    "            :return: Tokenized data \n",
    "        \"\"\"\n",
    "        return self.tokenizer(data['tagged_in_context'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    def create_datasets(self):\n",
    "        \"\"\"\n",
    "            Tokenizes train and test sets\n",
    "        \"\"\"\n",
    "        self.train_dataset = self.train_dataset.map(self.tokenize, batched=True)\n",
    "        self.test_dataset = self.test_dataset.map(self.tokenize, batched=True)\n",
    "\n",
    "    \n",
    "    def evaluate(self, eval_pred):\n",
    "        \"\"\"\n",
    "            Calculates Accuracy and F1 score. Creates confusion matrix.\n",
    "            :return: Accuracy and F1 values with dictionary\n",
    "        \"\"\"\n",
    "        accuracy_metric = load_metric(\"accuracy\")\n",
    "        f1_metric = load_metric(\"f1\")\n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "        f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        np.save(\"confusion_matrix.npy\", cm)\n",
    "        \n",
    "        return {\"Accuracy\" : accuracy, \"F1\" : f1}\n",
    "    \n",
    "    def train(self, b_size, epoch):\n",
    "\n",
    "        \"\"\"\n",
    "            Trains and evaluates the model. Logs results to wandb.\n",
    "            :param b_size: Batch size\n",
    "            :param epoch: Number of epochs\n",
    "        \"\"\"\n",
    "\n",
    "        #wandb.init(project=\"deberta-propaganda-detection-trainer\") # Logging to wandb\n",
    "\n",
    "        self.create_datasets()\n",
    "\n",
    "        batch_size = b_size\n",
    "        epochs = epoch\n",
    "        torch.mps.empty_cache()\n",
    "        log_time = int(self.train_dataset.num_rows / epochs)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./results\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            logging_strategy=\"epoch\",\n",
    "            logging_steps=log_time,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=epochs,\n",
    "            weight_decay=0.01,\n",
    "            use_mps_device=True,\n",
    "            report_to=\"wandb\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.test_dataset,\n",
    "            compute_metrics=self.evaluate \n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        results = trainer.evaluate()\n",
    "        print(results)\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "\n",
    "        \"\"\"\n",
    "            Plots confusion matrix and accuracy by class graph\n",
    "        \"\"\"\n",
    "\n",
    "        # Loading confusion matrix saved by evaluate function\n",
    "        cm = np.load(\"confusion_matrix.npy\")\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] \n",
    "        \n",
    "        df = pd.read_csv('propaganda_train.tsv', delimiter='\\t')\n",
    "\n",
    "        if self.n_labels == 2:\n",
    "            df.loc[df['label'] != \"not_propaganda\", 'label'] = \"propaganda\"\n",
    "        else:\n",
    "            df = df[df['label'] != 'not_propaganda']\n",
    "\n",
    "        labels = df['label'].unique()\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap='Blues')\n",
    "        plt.xticks(range(1, self.n_labels + 1), labels=labels, rotation ='vertical')\n",
    "        plt.yticks(range(1, self.n_labels + 1), labels=labels, rotation ='horizontal')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.margins(0.2) \n",
    "        plt.subplots_adjust(bottom = 0.15) \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Calculating accuracy per class\n",
    "        class_accuracy = 100 * cm_norm.diagonal() / cm_norm.sum(axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.barplot(x=labels, y=class_accuracy, palette='viridis')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Model Accuracy by Class')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "# Run Task 2\n",
    "# debertav3 = DebertaV3(task2_train_df, task2_test_df, len(task2_train_df[\"label\"].unique()))\n",
    "# debertav3.train(32, 1)\n",
    "# debertav3.plot_confusion_matrix()\n",
    "\n",
    "# Run Task 1\n",
    "debertav3 = DebertaV3(task1_train_df, task1_test_df, len(task1_train_df[\"label\"].unique()))\n",
    "debertav3.train(32, 1)\n",
    "debertav3.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with BERT Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Creating LSTM with BERT Word Embeddings model\n",
    "class LSTMWithBERTWordEmbeddings(nn.Module):\n",
    "    def __init__(self, n_classes, bert_model):\n",
    "        \"\"\"\n",
    "            Initializes model architecture\n",
    "            :param n_classes: Number of classes\n",
    "            :param bert_model: BERT model\n",
    "        \"\"\"\n",
    "        super(LSTMWithBERTWordEmbeddings, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, 128, num_layers=1, batch_first=True)\n",
    "        self.out = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "            Processes input through BERT and LSTM to generate class predictions.\n",
    "            :param input_ids: Tensor of token IDs from tokenizer\n",
    "            :param attention_mask: Tensor representing the attention mask\n",
    "            :return: Output tensor from the final linear layer\n",
    "        \"\"\"\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        last_hidden_state = outputs['last_hidden_state']\n",
    "        _, (hidden, _) = self.lstm(last_hidden_state)  # BERT output to LSTM\n",
    "        hidden = self.drop(hidden.squeeze(0))\n",
    "        return self.out(hidden)\n",
    "    \n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        \"\"\"\n",
    "           Initializes custom dataset.\n",
    "           :param texts: Sentences\n",
    "           :param labels: Labels\n",
    "           :param tokenizer: Tokenizer\n",
    "           :param max_len: Maximum sentence length\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            Encodes and returns data from the given index\n",
    "            :param idx: Index\n",
    "            :return: dictionary containing input_ids, attention_mask and labels\n",
    "        \"\"\"\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class LBWE:\n",
    "\n",
    "    def __init__(self, train, test, b_size, epoch, num_classes):\n",
    "\n",
    "        \"\"\"\n",
    "           Initializes variables. Creates Dataset from train and test datasets. Creates model, tokenizer, optimizer and loss function. Creates dataloaders.\n",
    "           :param train: Train set\n",
    "           :param test: Test set\n",
    "           :param b_size: Batch size\n",
    "           :param epoch: Number of epoch\n",
    "           :param num_classes: Number of classes\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Loading BERT Model and Tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        train_dataset = LSTMDataset(train[\"tagged_in_context\"], train[\"label\"], self.tokenizer, max_len=128)\n",
    "        test_dataset = LSTMDataset(test[\"tagged_in_context\"], test[\"label\"], self.tokenizer, max_len=128)\n",
    "\n",
    "        # Creating dataloaders, defining model, optimizer and loss functions\n",
    "        self.num_epochs = epoch\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=b_size)\n",
    "\n",
    "        self.model = LSTMWithBERTWordEmbeddings(num_classes, bert_model)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=2e-5)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.device = torch.device(\"mps\")\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        \"\"\"\n",
    "            Trains and evaluates the model. Logs results to wandb.\n",
    "        \"\"\"\n",
    "\n",
    "        # Training\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss, total_accuracy = 0, 0\n",
    "\n",
    "            for data in tqdm(self.train_loader):\n",
    "                input_ids = data['input_ids'].to(self.device)\n",
    "                attention_mask = data['attention_mask'].to(self.device)\n",
    "                labels = data['labels'].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_accuracy += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(self.train_loader)\n",
    "            avg_train_accuracy = total_accuracy / len(self.train_loader.dataset)\n",
    "            wandb.define_metric(\"epoch\")\n",
    "            wandb.define_metric(\"train_loss\", step_metric=\"epoch\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"epoch\": epoch\n",
    "                })\n",
    "            \n",
    "            wandb.define_metric(\"train_accuracy\", step_metric=\"epoch\")\n",
    "            wandb.log({\"train_accuracy\": avg_train_accuracy,\n",
    "                \"epoch\": epoch})\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs}, Train Loss: {avg_train_loss:.5f}, Train Accuracy: {avg_train_accuracy:.5f}\")\n",
    "\n",
    "            # Evaluation\n",
    "            self.model.eval()\n",
    "            total_test_loss, total_test_accuracy = 0, 0\n",
    "            predictions = []\n",
    "            true_labels = []\n",
    "            with torch.no_grad():\n",
    "                for data in self.test_loader:\n",
    "                    input_ids = data['input_ids'].to(self.device)\n",
    "                    attention_mask = data['attention_mask'].to(self.device)\n",
    "                    labels = data['labels'].to(self.device)\n",
    "\n",
    "                    outputs = self.model(input_ids, attention_mask)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "\n",
    "                    total_test_loss += loss.item()\n",
    "                    total_test_accuracy += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    predictions.extend(preds.tolist())\n",
    "                    true_labels.extend(labels.tolist()) \n",
    "\n",
    "            avg_test_loss = total_test_loss / len(self.test_loader)\n",
    "            avg_test_accuracy = total_test_accuracy / len(self.test_loader.dataset)\n",
    "            f1 = f1_score(true_labels, predictions, average=\"macro\") \n",
    "            wandb.define_metric(\"test_loss\", step_metric=\"epoch\")\n",
    "            wandb.log({\"test_loss\": avg_test_loss,\n",
    "                \"epoch\": epoch})\n",
    "            wandb.define_metric(\"test_accuracy\", step_metric=\"epoch\")\n",
    "            wandb.log({\"test_accuracy\": avg_test_accuracy,\n",
    "                \"epoch\": epoch})\n",
    "            wandb.define_metric(\"test_f1\", step_metric=\"epoch\")\n",
    "            wandb.log({\"test_f1\": f1,\n",
    "                \"epoch\": epoch})\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs}, Test Loss: {avg_test_loss:.5f}, Test Accuracy: {avg_test_accuracy:.5f}\")\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "\n",
    "        \"\"\"\n",
    "            Plots confusion matrix and accuracy by class graph\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.test_loader:\n",
    "                input_ids = data['input_ids'].to(self.device)\n",
    "                attention_mask = data['attention_mask'].to(self.device)\n",
    "                labels = data['labels'].to(self.device)\n",
    "                y_true.extend(labels.tolist()) \n",
    "\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                y_pred.extend(preds.tolist())\n",
    "\n",
    "\n",
    "        df = pd.read_csv('propaganda_train.tsv', delimiter='\\t')\n",
    "        \n",
    "        if self.num_classes == 2:\n",
    "            df.loc[df['label'] != \"not_propaganda\", 'label'] = \"propaganda\"\n",
    "        else:\n",
    "            df = df[df['label'] != 'not_propaganda']\n",
    "        labels = df['label'].unique()\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the confusion matrix\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap='Blues')\n",
    "        plt.xticks(range(1, self.num_classes + 1), labels=labels, rotation ='vertical')\n",
    "        plt.yticks(range(1, self.num_classes + 1), labels=labels, rotation ='horizontal')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.margins(0.2) \n",
    "        plt.subplots_adjust(bottom = 0.15) \n",
    "        plt.show()\n",
    "\n",
    "        class_accuracy = 100 * cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.barplot(x=labels, y=class_accuracy, palette='viridis')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Model Accuracy by Class')\n",
    "        plt.ylim(0, 100)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "# Run Task 2\n",
    "# lbwe = LBWE(task2_train_df, task2_test_df, 32, 1, len(task2_train_df[\"label\"].unique()))\n",
    "# lbwe.train()\n",
    "# lbwe.plot_confusion_matrix()\n",
    "\n",
    "\n",
    "# Run Task 1\n",
    "lbwe = LBWE(task1_train_df, task1_test_df, 32, 1, len(task1_train_df[\"label\"].unique()))\n",
    "lbwe.train()\n",
    "lbwe.plot_confusion_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self,train,test):\n",
    "\n",
    "        \"\"\"\n",
    "            Initializes train, test sets and word2vec model.\n",
    "            :param train: Train set\n",
    "            :param test: Test set\n",
    "        \"\"\"\n",
    "\n",
    "        self.train_df = train\n",
    "        self.test_df = test\n",
    "        # Loading word2vec from local\n",
    "        self.word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "    # Data preprocessing\n",
    "    def preprocess_text(self,text):\n",
    "        \"\"\"\n",
    "            Preprocesses text\n",
    "            :param text: Sentence\n",
    "            :return: Processed text\n",
    "        \"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "        return ' '.join(filtered_text)\n",
    "    \n",
    "    def normalise_dataframes(self):\n",
    "        \"\"\"\n",
    "            Applies preprocessing to train and test dataframes\n",
    "        \"\"\"\n",
    "        self.train_df['normalized_tagged_in_context'] = self.train_df['tagged_in_context'].apply(self.preprocess_text)\n",
    "        self.test_df['normalized_tagged_in_context'] = self.test_df['tagged_in_context'].apply(self.preprocess_text)\n",
    "\n",
    "    def create_sentence_vector(self,word2vec_model, sentence):\n",
    "        \"\"\"\n",
    "            Creates sentence vectors with word2vec\n",
    "            :param word2vec_model: Word2vec model\n",
    "            :param sentence: Sentence\n",
    "            :return: Sentence vector\n",
    "        \"\"\"\n",
    "        words = sentence.split()\n",
    "        word_vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n",
    "        if not word_vectors:\n",
    "            return np.zeros(word2vec_model.vector_size)\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    \n",
    "    def create_train_test(self):\n",
    "\n",
    "        \"\"\"\n",
    "            Creates train and test sets for training\n",
    "            :param word2vec_model: Word2vec model\n",
    "            :param sentence: Sentence\n",
    "            :return: Created train and test sets\n",
    "        \"\"\"\n",
    "\n",
    "        self.normalise_dataframes()\n",
    "\n",
    "        # Calculates sentence vector for all sentences in the dataframes\n",
    "        self.train_df['doc_vector'] = self.train_df['normalized_tagged_in_context'].apply(lambda doc: self.create_sentence_vector(self.word2vec_model, doc))\n",
    "        self.test_df['doc_vector'] = self.test_df['normalized_tagged_in_context'].apply(lambda doc: self.create_sentence_vector(self.word2vec_model, doc))\n",
    "\n",
    "        # Creating x_train, y_train, x_test and y_test. Assigning vectors to x and assigning labels to y\n",
    "        x_train = np.vstack(self.train_df['doc_vector'])\n",
    "        y_train = self.train_df['label'].values\n",
    "        x_test = np.vstack(self.test_df['doc_vector'])\n",
    "        y_test = self.test_df['label'].values\n",
    "\n",
    "        return x_train,y_train,x_test,y_test\n",
    "    \n",
    "\n",
    "    def train(self,x_train,y_train,x_test,y_test):\n",
    "\n",
    "        \"\"\"\n",
    "            Trains the model\n",
    "            :param x_train: Training sentences\n",
    "            :param y_train: Training labels\n",
    "            :param x_tets: Test sentences\n",
    "            :param y_test: Test labels\n",
    "            :return: GridSearchCV results\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        #Running GridSearchCV\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=3, scoring='f1_macro', cv=2)\n",
    "        grid_search.fit(x_train, y_train)\n",
    "        results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def plot_results(self, results):\n",
    "\n",
    "        \"\"\"\n",
    "            Plots results with hetmap for every kernel\n",
    "            :param results: GridSearchCV results\n",
    "        \"\"\"\n",
    "\n",
    "        # Creating subplots for every kernel\n",
    "        kernels = results['param_kernel'].unique()\n",
    "        num_kernels = len(kernels)\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for idx, kernel in enumerate(kernels):\n",
    "            kernel_results = results[results['param_kernel'] == kernel]\n",
    "            \n",
    "            pivot_table = kernel_results.pivot_table(values='mean_test_score', index='param_C', columns='param_gamma', aggfunc=np.max)\n",
    "            \n",
    "            sns.heatmap(pivot_table, ax=axes[idx], annot=True, fmt=\".3f\", cmap=\"coolwarm\", cbar_kws={'label': 'F1 Score'})\n",
    "            axes[idx].set_title(f'Task - 1 SVM F1 Score Optimization for Kernel: {kernel}')\n",
    "            axes[idx].set_xlabel('Gamma')\n",
    "            axes[idx].set_ylabel('C')\n",
    "\n",
    "        for ax in axes[num_kernels:]:\n",
    "            fig.delaxes(ax)\n",
    "\n",
    "        fig.tight_layout(pad=3.0)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self,x_train, y_train, kernel_param, c_param, gamma_param): \n",
    "\n",
    "        \"\"\"\n",
    "            Plots confusion matrix\n",
    "            :param x_train: Training sentences\n",
    "            :param y_train: Training labels\n",
    "            :param kernel_param: Kernel type\n",
    "            :param c_param: C value\n",
    "            :param gamma_param: Gamma value\n",
    "        \"\"\"   \n",
    "\n",
    "        # Train with best hyperparameters\n",
    "        svm_classifier = SVC(kernel=kernel_param, C=c_param, gamma=gamma_param)\n",
    "        svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = svm_classifier.predict(x_test)\n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        cm_normalized = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "        df = pd.read_csv('propaganda_train.tsv', delimiter='\\t')\n",
    "        df.loc[df['label'] != \"not_propaganda\", 'label'] = \"propaganda\"\n",
    "        labels = df['label'].unique()\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap='Blues')\n",
    "        plt.xticks(range(1,len(labels) + 1), labels=labels, rotation ='vertical')\n",
    "        plt.yticks(range(1,len(labels) + 1), labels=labels, rotation ='horizontal')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Run Task 1\n",
    "# svm = SVM(task1_train_df,task1_test_df)\n",
    "# x_train,y_train,x_test,y_test = svm.create_train_test()\n",
    "# results = svm.train(x_train,y_train,x_test,y_test)\n",
    "# svm.plot_results(results)\n",
    "# svm.plot_confusion_matrix(x_train,y_train,\"rbf\",1,1)\n",
    "\n",
    "# Run Task 2\n",
    "svm = SVM(task2_train_df,task2_test_df)\n",
    "x_train,y_train,x_test,y_test = svm.create_train_test()\n",
    "results = svm.train(x_train,y_train,x_test,y_test)\n",
    "svm.plot_results(results)\n",
    "svm.plot_confusion_matrix(x_train,y_train,\"rbf\",1,1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
